{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eee4a6b",
   "metadata": {},
   "source": [
    "# Tarefa 5 - Treinando Modelos Densos Estáticos\n",
    "## Alunos\n",
    "- Yago César\n",
    "- Samuel Morais\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f32676",
   "metadata": {},
   "source": [
    "## Imports e logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "223e8da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from time import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fc21e6",
   "metadata": {},
   "source": [
    "## Lendo o corpus pré-processado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7771cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [nada, queira, voltar, tempo, refazer, vida, t...\n",
       "1        [lidando, mudanças, humor, tido, muitas, mudan...\n",
       "2        [noiva, usar, voce, ja, sabe, pergunte, nao, f...\n",
       "3        [muitas, vezes, consigo, trabalhar, cerca, hor...\n",
       "4        [quais, ações, sentindo, ansioso, procurando, ...\n",
       "                               ...                        \n",
       "50962    [vivo, outras, fazendo, péssimo, trabalho, viv...\n",
       "50963    [parabéns, amigo, tapa, buraco, depende, quer,...\n",
       "50964    [ansiedade, doente, epiléptico, ansiedade, def...\n",
       "50965    [passei, período, difícil, durante, últimos, 3...\n",
       "50966    [sair, terapia, desde, 14, anos, finalmente, d...\n",
       "Name: text, Length: 50967, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/TokenizedSentences.csv\")\n",
    "\n",
    "# Transformando as strings \"[...strings]\" para listas de strings\n",
    "df['text'] = df['text'].apply(ast.literal_eval)\n",
    "\n",
    "corpus = df['text'].tolist()\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8a8fa9",
   "metadata": {},
   "source": [
    "## Modelo Word2Vec\n",
    "### Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5abdc6",
   "metadata": {},
   "source": [
    "#### Opções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef83f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'skip-gram' ou 'cbow'\n",
    "TRAINING_ALGORITHM = 'skip-gram'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd48701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.01\n",
      "Time to train the model: 2.21 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28877/2822979235.py:21: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  model.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "w2v_model = Word2Vec(\n",
    "    vector_size=300, # dimensionalidade do vetor de palavras\n",
    "    window=5,        # distância máxima entre a palavra atual e a palavra predita em uma sentença\n",
    "    min_count=5,     # ignora todas as palavras com uma frequência total menor que esse valor\n",
    "    sample=1e-5,     # limiar para configurar quais palavras de maior frequência são aleatoriamente downsampled\n",
    "    sg=1 if TRAINING_ALGORITHM == 'skip-gram' else 0 # CBOW = 0 ; skip-gram = 1\n",
    ")\n",
    "\n",
    "t = time()\n",
    "w2v_model.build_vocab(corpus, progress_per=10000)\n",
    "print(f'Time to build vocab: {round((time() - t) / 60, 2)}')\n",
    "\n",
    "t = time()\n",
    "# report_delay - número de segundos para esperar antes de reportar o progresso\n",
    "w2v_model.train(corpus, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "print(f'Time to train the model: {round((time() - t) / 60, 2)} mins')\n",
    "\n",
    "w2v_model.save('word2vec_{TRAINING_ALGORITHM}.model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c11b60",
   "metadata": {},
   "source": [
    "### Exploração semântica\n",
    "#### Palavras mais similares\n",
    "\n",
    "Tomando como base o contexto do corpus, as 4 palavras escohidas foram:\n",
    "- depressão;\n",
    "- ansiedade;\n",
    "- medo;\n",
    "- suicídio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cf269c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ataques', 0.8192235231399536),\n",
       " ('ataque', 0.7734318971633911),\n",
       " ('ansiedade', 0.6586445569992065),\n",
       " ('pânicoansiedade', 0.5356523990631104),\n",
       " ('ansioso', 0.4834514856338501),\n",
       " ('sintomas', 0.45120304822921753),\n",
       " ('tendo', 0.45071545243263245),\n",
       " ('batimentos', 0.4454892873764038),\n",
       " ('ansiedadepânico', 0.44178271293640137),\n",
       " ('cardíaco', 0.4200853109359741)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"depressão\"], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61b2db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('depressão', 0.6619756817817688),\n",
       " ('pânico', 0.6586444973945618),\n",
       " ('social', 0.657738983631134),\n",
       " ('ataques', 0.608400821685791),\n",
       " ('diagnosticado', 0.5388233661651611)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"ansiedade\"], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ac1092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('posso', 0.5136370658874512),\n",
       " ('causa', 0.5071543455123901),\n",
       " ('morrer', 0.4897680878639221),\n",
       " ('preocupado', 0.4877718985080719),\n",
       " ('ideia', 0.48593705892562866)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"medo\"], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1590d071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('matar', 0.6484552621841431),\n",
       " ('suicida', 0.5514351725578308),\n",
       " ('cometer', 0.5420529842376709),\n",
       " ('tentativa', 0.5321749448776245),\n",
       " ('morte', 0.5142024755477905)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"suicídio\"], topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093170c5",
   "metadata": {},
   "source": [
    "#### Similaridade semântica entre palavras\n",
    "\n",
    "Palavras escolhidas:\n",
    "- ansiedade;\n",
    "- depressão;\n",
    "- suicídio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbdf972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6619757"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity('ansiedade', 'depressão')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f9d80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14742094"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity('suicídio', 'ansiedade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf46450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36058834"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity('depressão', 'suicídio')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37aed87",
   "metadata": {},
   "source": [
    "#### Analogia semântica\n",
    "\n",
    "Analogias escolhidas:\n",
    "- **\"suicídio + depressão\"**: entender quais palavras entram no contexto da combinação entre **\"suicídio\"** e **\"depressão\"**.\n",
    "- **\"depressão + ansiedade - suicídio\"**: entender o que há em comum entre **depressão** e **ansiedade** sem levar em conta desfechos extremos (**suicídio**).\n",
    "- **\"psicólogo + saúde\"**: buscar palavras que representem o papel do **psicólogo** na melhora da **saúde** dos pacientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d166fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('suicida', 0.6331512331962585),\n",
       " ('matar', 0.5774985551834106),\n",
       " ('suicidas', 0.5762591361999512),\n",
       " ('deprimido', 0.5468285083770752),\n",
       " ('mental', 0.5226360559463501),\n",
       " ('diagnosticado', 0.5204373598098755),\n",
       " ('vida', 0.5046091675758362),\n",
       " ('ansiedade', 0.49066269397735596),\n",
       " ('transtorno', 0.47831130027770996),\n",
       " ('pensamentos', 0.4756019711494446)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# suicídio + depressão\n",
    "w2v_model.wv.most_similar(positive=[\"suicídio\", \"depressão\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2ef90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('social', 0.5230732560157776),\n",
       " ('pânico', 0.4886881709098816),\n",
       " ('ataques', 0.4742621183395386),\n",
       " ('diagnosticado', 0.4650210738182068),\n",
       " ('transtorno', 0.454802006483078),\n",
       " ('estresse', 0.44036513566970825),\n",
       " ('recentemente', 0.43963363766670227),\n",
       " ('severa', 0.4338925778865814),\n",
       " ('sintomas', 0.4259622097015381),\n",
       " ('geral', 0.42242783308029175)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# depressão + ansiedade - suicídio\n",
    "w2v_model.wv.most_similar(positive=[\"depressão\", \"ansiedade\"], negative=['suicídio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f65c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mental', 0.6679843664169312),\n",
       " ('terapeuta', 0.6156370639801025),\n",
       " ('médico', 0.5743861198425293),\n",
       " ('psiquiatra', 0.5581804513931274),\n",
       " ('terapia', 0.5561575889587402),\n",
       " ('consultar', 0.5146474838256836),\n",
       " ('ajuda', 0.5139002203941345),\n",
       " ('problemas', 0.4710984528064728),\n",
       " ('encaminhou', 0.4589638411998749),\n",
       " ('ajudar', 0.4547247588634491)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# psicólogo + saúde\n",
    "w2v_model.wv.most_similar(positive=[\"psicólogo\", \"saúde\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dca814",
   "metadata": {},
   "source": [
    "## Modelo Doc2Vec\n",
    "### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b7dbf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-19 23:26:48,647 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d300,n5,w5,mc5,s0.001,t3>', 'datetime': '2025-10-19T23:26:48.647123', 'gensim': '4.4.0', 'python': '3.11.2 (main, Apr 28 2025, 14:11:48) [GCC 12.2.0]', 'platform': 'Linux-6.1.0-40-amd64-x86_64-with-glibc2.36', 'event': 'created'}\n",
      "2025-10-19 23:26:48,651 : INFO : collecting all words and their counts\n",
      "2025-10-19 23:26:48,652 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2025-10-19 23:26:48,739 : INFO : PROGRESS: at example #10000, processed 609329 words (7043991 words/s), 39103 word types, 10000 tags\n",
      "2025-10-19 23:26:48,807 : INFO : PROGRESS: at example #20000, processed 1203381 words (8855569 words/s), 56838 word types, 20000 tags\n",
      "2025-10-19 23:26:48,881 : INFO : PROGRESS: at example #30000, processed 1810721 words (8274186 words/s), 71456 word types, 30000 tags\n",
      "2025-10-19 23:26:48,955 : INFO : PROGRESS: at example #40000, processed 2414286 words (8151457 words/s), 84054 word types, 40000 tags\n",
      "2025-10-19 23:26:49,044 : INFO : PROGRESS: at example #50000, processed 3022407 words (6875642 words/s), 95615 word types, 50000 tags\n",
      "2025-10-19 23:26:49,189 : INFO : collected 96724 word types and 50967 unique tags from a corpus of 50967 examples and 3081926 words\n",
      "2025-10-19 23:26:49,189 : INFO : Creating a fresh vocabulary\n",
      "2025-10-19 23:26:49,245 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 23082 unique words (23.86% of original 96724, drops 73642)', 'datetime': '2025-10-19T23:26:49.245914', 'gensim': '4.4.0', 'python': '3.11.2 (main, Apr 28 2025, 14:11:48) [GCC 12.2.0]', 'platform': 'Linux-6.1.0-40-amd64-x86_64-with-glibc2.36', 'event': 'prepare_vocab'}\n",
      "2025-10-19 23:26:49,246 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 2977868 word corpus (96.62% of original 3081926, drops 104058)', 'datetime': '2025-10-19T23:26:49.246455', 'gensim': '4.4.0', 'python': '3.11.2 (main, Apr 28 2025, 14:11:48) [GCC 12.2.0]', 'platform': 'Linux-6.1.0-40-amd64-x86_64-with-glibc2.36', 'event': 'prepare_vocab'}\n",
      "2025-10-19 23:26:49,314 : INFO : deleting the raw counts dictionary of 96724 items\n",
      "2025-10-19 23:26:49,316 : INFO : sample=0.001 downsamples 30 most-common words\n",
      "2025-10-19 23:26:49,316 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 2874933.2063351665 word corpus (96.5%% of prior 2977868)', 'datetime': '2025-10-19T23:26:49.316876', 'gensim': '4.4.0', 'python': '3.11.2 (main, Apr 28 2025, 14:11:48) [GCC 12.2.0]', 'platform': 'Linux-6.1.0-40-amd64-x86_64-with-glibc2.36', 'event': 'prepare_vocab'}\n",
      "2025-10-19 23:26:49,427 : INFO : estimated required memory for 23082 words and 300 dimensions: 138291600 bytes\n",
      "2025-10-19 23:26:49,427 : INFO : resetting layer weights\n",
      "2025-10-19 23:26:49,504 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 23082 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-10-19T23:26:49.504029', 'gensim': '4.4.0', 'python': '3.11.2 (main, Apr 28 2025, 14:11:48) [GCC 12.2.0]', 'platform': 'Linux-6.1.0-40-amd64-x86_64-with-glibc2.36', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-19 23:26:50,517 : INFO : EPOCH 0 - PROGRESS: at 28.43% examples, 820700 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:26:51,518 : INFO : EPOCH 0 - PROGRESS: at 57.20% examples, 828894 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:26:52,528 : INFO : EPOCH 0 - PROGRESS: at 86.39% examples, 835633 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:26:52,939 : INFO : EPOCH 0: training on 3081926 raw words (2925712 effective words) took 3.4s, 852090 effective words/s\n",
      "2025-10-19 23:26:53,946 : INFO : EPOCH 1 - PROGRESS: at 29.65% examples, 864331 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:26:54,953 : INFO : EPOCH 1 - PROGRESS: at 59.40% examples, 861949 words/s, in_qsize 6, out_qsize 0\n",
      "2025-10-19 23:26:55,954 : INFO : EPOCH 1 - PROGRESS: at 90.72% examples, 879010 words/s, in_qsize 6, out_qsize 0\n",
      "2025-10-19 23:26:56,255 : INFO : EPOCH 1: training on 3081926 raw words (2926142 effective words) took 3.3s, 883010 effective words/s\n",
      "2025-10-19 23:26:57,266 : INFO : EPOCH 2 - PROGRESS: at 31.31% examples, 906253 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:26:58,277 : INFO : EPOCH 2 - PROGRESS: at 64.21% examples, 928131 words/s, in_qsize 6, out_qsize 0\n",
      "2025-10-19 23:26:59,293 : INFO : EPOCH 2 - PROGRESS: at 97.03% examples, 934190 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:26:59,380 : INFO : EPOCH 2: training on 3081926 raw words (2925615 effective words) took 3.1s, 936431 effective words/s\n",
      "2025-10-19 23:27:00,402 : INFO : EPOCH 3 - PROGRESS: at 31.00% examples, 888383 words/s, in_qsize 6, out_qsize 0\n",
      "2025-10-19 23:27:01,408 : INFO : EPOCH 3 - PROGRESS: at 62.63% examples, 902446 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:02,418 : INFO : EPOCH 3 - PROGRESS: at 94.00% examples, 903341 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:02,601 : INFO : EPOCH 3: training on 3081926 raw words (2926130 effective words) took 3.2s, 909076 effective words/s\n",
      "2025-10-19 23:27:03,612 : INFO : EPOCH 4 - PROGRESS: at 32.31% examples, 934338 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:04,617 : INFO : EPOCH 4 - PROGRESS: at 62.52% examples, 907796 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:05,623 : INFO : EPOCH 4 - PROGRESS: at 94.59% examples, 914008 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:05,809 : INFO : EPOCH 4: training on 3081926 raw words (2925647 effective words) took 3.2s, 912378 effective words/s\n",
      "2025-10-19 23:27:06,830 : INFO : EPOCH 5 - PROGRESS: at 30.33% examples, 870400 words/s, in_qsize 6, out_qsize 0\n",
      "2025-10-19 23:27:07,852 : INFO : EPOCH 5 - PROGRESS: at 63.18% examples, 905048 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:08,862 : INFO : EPOCH 5 - PROGRESS: at 94.83% examples, 907856 words/s, in_qsize 6, out_qsize 0\n",
      "2025-10-19 23:27:09,031 : INFO : EPOCH 5: training on 3081926 raw words (2925587 effective words) took 3.2s, 908356 effective words/s\n",
      "2025-10-19 23:27:10,038 : INFO : EPOCH 6 - PROGRESS: at 29.36% examples, 855387 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:11,048 : INFO : EPOCH 6 - PROGRESS: at 60.95% examples, 884449 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:12,050 : INFO : EPOCH 6 - PROGRESS: at 91.09% examples, 881299 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:12,359 : INFO : EPOCH 6: training on 3081926 raw words (2926403 effective words) took 3.3s, 880077 effective words/s\n",
      "2025-10-19 23:27:13,365 : INFO : EPOCH 7 - PROGRESS: at 32.01% examples, 930284 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:14,370 : INFO : EPOCH 7 - PROGRESS: at 62.27% examples, 905467 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:15,372 : INFO : EPOCH 7 - PROGRESS: at 93.40% examples, 904694 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:15,609 : INFO : EPOCH 7: training on 3081926 raw words (2926104 effective words) took 3.2s, 900815 effective words/s\n",
      "2025-10-19 23:27:16,628 : INFO : EPOCH 8 - PROGRESS: at 32.01% examples, 918838 words/s, in_qsize 6, out_qsize 0\n",
      "2025-10-19 23:27:17,641 : INFO : EPOCH 8 - PROGRESS: at 64.21% examples, 923927 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:18,648 : INFO : EPOCH 8 - PROGRESS: at 95.77% examples, 921519 words/s, in_qsize 6, out_qsize 0\n",
      "2025-10-19 23:27:18,789 : INFO : EPOCH 8: training on 3081926 raw words (2926107 effective words) took 3.2s, 920631 effective words/s\n",
      "2025-10-19 23:27:19,793 : INFO : EPOCH 9 - PROGRESS: at 29.98% examples, 875850 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:20,804 : INFO : EPOCH 9 - PROGRESS: at 61.59% examples, 894125 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:21,822 : INFO : EPOCH 9 - PROGRESS: at 93.40% examples, 898713 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:22,080 : INFO : EPOCH 9: training on 3081926 raw words (2925943 effective words) took 3.3s, 889705 effective words/s\n",
      "2025-10-19 23:27:23,089 : INFO : EPOCH 10 - PROGRESS: at 29.03% examples, 843118 words/s, in_qsize 6, out_qsize 0\n",
      "2025-10-19 23:27:24,092 : INFO : EPOCH 10 - PROGRESS: at 61.91% examples, 900109 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:25,122 : INFO : EPOCH 10 - PROGRESS: at 90.06% examples, 864844 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:25,478 : INFO : EPOCH 10: training on 3081926 raw words (2925736 effective words) took 3.4s, 861411 effective words/s\n",
      "2025-10-19 23:27:26,482 : INFO : EPOCH 11 - PROGRESS: at 25.09% examples, 734768 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:27,485 : INFO : EPOCH 11 - PROGRESS: at 51.38% examples, 747466 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:28,492 : INFO : EPOCH 11 - PROGRESS: at 78.43% examples, 760237 words/s, in_qsize 6, out_qsize 0\n",
      "2025-10-19 23:27:29,348 : INFO : EPOCH 11: training on 3081926 raw words (2926176 effective words) took 3.9s, 756504 effective words/s\n",
      "2025-10-19 23:27:30,367 : INFO : EPOCH 12 - PROGRESS: at 29.36% examples, 844685 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:31,398 : INFO : EPOCH 12 - PROGRESS: at 56.54% examples, 805427 words/s, in_qsize 6, out_qsize 0\n",
      "2025-10-19 23:27:32,403 : INFO : EPOCH 12 - PROGRESS: at 80.06% examples, 765467 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:33,214 : INFO : EPOCH 12: training on 3081926 raw words (2926166 effective words) took 3.9s, 757251 effective words/s\n",
      "2025-10-19 23:27:34,217 : INFO : EPOCH 13 - PROGRESS: at 23.88% examples, 698087 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:35,218 : INFO : EPOCH 13 - PROGRESS: at 49.45% examples, 720418 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:36,226 : INFO : EPOCH 13 - PROGRESS: at 77.20% examples, 748202 words/s, in_qsize 6, out_qsize 0\n",
      "2025-10-19 23:27:37,105 : INFO : EPOCH 13: training on 3081926 raw words (2925990 effective words) took 3.9s, 752408 effective words/s\n",
      "2025-10-19 23:27:38,111 : INFO : EPOCH 14 - PROGRESS: at 24.75% examples, 724585 words/s, in_qsize 6, out_qsize 0\n",
      "2025-10-19 23:27:39,113 : INFO : EPOCH 14 - PROGRESS: at 52.38% examples, 761525 words/s, in_qsize 6, out_qsize 0\n",
      "2025-10-19 23:27:40,114 : INFO : EPOCH 14 - PROGRESS: at 82.07% examples, 796171 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:40,747 : INFO : EPOCH 14: training on 3081926 raw words (2925970 effective words) took 3.6s, 804007 effective words/s\n",
      "2025-10-19 23:27:41,769 : INFO : EPOCH 15 - PROGRESS: at 31.31% examples, 897296 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:42,774 : INFO : EPOCH 15 - PROGRESS: at 62.52% examples, 903032 words/s, in_qsize 6, out_qsize 0\n",
      "2025-10-19 23:27:43,776 : INFO : EPOCH 15 - PROGRESS: at 88.34% examples, 853121 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:44,239 : INFO : EPOCH 15: training on 3081926 raw words (2925910 effective words) took 3.5s, 838432 effective words/s\n",
      "2025-10-19 23:27:45,254 : INFO : EPOCH 16 - PROGRESS: at 29.36% examples, 848327 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:46,259 : INFO : EPOCH 16 - PROGRESS: at 60.02% examples, 868836 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:47,262 : INFO : EPOCH 16 - PROGRESS: at 88.05% examples, 851746 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:47,793 : INFO : EPOCH 16: training on 3081926 raw words (2925907 effective words) took 3.6s, 823768 effective words/s\n",
      "2025-10-19 23:27:48,795 : INFO : EPOCH 17 - PROGRESS: at 28.48% examples, 830610 words/s, in_qsize 6, out_qsize 0\n",
      "2025-10-19 23:27:49,802 : INFO : EPOCH 17 - PROGRESS: at 58.53% examples, 849964 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:50,810 : INFO : EPOCH 17 - PROGRESS: at 89.06% examples, 862772 words/s, in_qsize 6, out_qsize 0\n",
      "2025-10-19 23:27:51,172 : INFO : EPOCH 17: training on 3081926 raw words (2926044 effective words) took 3.4s, 866407 effective words/s\n",
      "2025-10-19 23:27:52,183 : INFO : EPOCH 18 - PROGRESS: at 28.11% examples, 813891 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:53,199 : INFO : EPOCH 18 - PROGRESS: at 53.86% examples, 777015 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:54,228 : INFO : EPOCH 18 - PROGRESS: at 84.83% examples, 811722 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:54,748 : INFO : EPOCH 18: training on 3081926 raw words (2925806 effective words) took 3.6s, 818843 effective words/s\n",
      "2025-10-19 23:27:55,750 : INFO : EPOCH 19 - PROGRESS: at 31.31% examples, 914488 words/s, in_qsize 6, out_qsize 0\n",
      "2025-10-19 23:27:56,775 : INFO : EPOCH 19 - PROGRESS: at 60.35% examples, 870080 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:57,775 : INFO : EPOCH 19 - PROGRESS: at 91.09% examples, 878526 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:27:58,075 : INFO : EPOCH 19: training on 3081926 raw words (2926041 effective words) took 3.3s, 879824 effective words/s\n",
      "2025-10-19 23:27:59,080 : INFO : EPOCH 20 - PROGRESS: at 30.34% examples, 883956 words/s, in_qsize 6, out_qsize 0\n",
      "2025-10-19 23:28:00,091 : INFO : EPOCH 20 - PROGRESS: at 62.89% examples, 912242 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:28:01,103 : INFO : EPOCH 20 - PROGRESS: at 95.11% examples, 918516 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:28:01,269 : INFO : EPOCH 20: training on 3081926 raw words (2925769 effective words) took 3.2s, 916495 effective words/s\n",
      "2025-10-19 23:28:02,281 : INFO : EPOCH 21 - PROGRESS: at 31.00% examples, 898390 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:28:03,284 : INFO : EPOCH 21 - PROGRESS: at 62.63% examples, 909022 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:28:04,285 : INFO : EPOCH 21 - PROGRESS: at 92.13% examples, 891760 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:28:04,542 : INFO : EPOCH 21: training on 3081926 raw words (2925880 effective words) took 3.3s, 894857 effective words/s\n",
      "2025-10-19 23:28:05,547 : INFO : EPOCH 22 - PROGRESS: at 28.80% examples, 837429 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:28:06,565 : INFO : EPOCH 22 - PROGRESS: at 59.40% examples, 858104 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:28:07,573 : INFO : EPOCH 22 - PROGRESS: at 90.72% examples, 874306 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:28:07,911 : INFO : EPOCH 22: training on 3081926 raw words (2926254 effective words) took 3.4s, 868948 effective words/s\n",
      "2025-10-19 23:28:08,916 : INFO : EPOCH 23 - PROGRESS: at 29.32% examples, 856343 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:28:09,916 : INFO : EPOCH 23 - PROGRESS: at 60.95% examples, 889072 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:28:10,920 : INFO : EPOCH 23 - PROGRESS: at 92.74% examples, 899522 words/s, in_qsize 6, out_qsize 0\n",
      "2025-10-19 23:28:11,204 : INFO : EPOCH 23: training on 3081926 raw words (2925866 effective words) took 3.3s, 889044 effective words/s\n",
      "2025-10-19 23:28:12,220 : INFO : EPOCH 24 - PROGRESS: at 29.36% examples, 846605 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:28:13,225 : INFO : EPOCH 24 - PROGRESS: at 60.02% examples, 867964 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:28:14,227 : INFO : EPOCH 24 - PROGRESS: at 89.06% examples, 860915 words/s, in_qsize 6, out_qsize 0\n",
      "2025-10-19 23:28:14,610 : INFO : EPOCH 24: training on 3081926 raw words (2925829 effective words) took 3.4s, 859379 effective words/s\n",
      "2025-10-19 23:28:15,627 : INFO : EPOCH 25 - PROGRESS: at 24.46% examples, 706705 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:28:16,631 : INFO : EPOCH 25 - PROGRESS: at 54.84% examples, 793762 words/s, in_qsize 6, out_qsize 1\n",
      "2025-10-19 23:28:17,640 : INFO : EPOCH 25 - PROGRESS: at 82.31% examples, 793809 words/s, in_qsize 6, out_qsize 0\n",
      "2025-10-19 23:28:18,245 : INFO : EPOCH 25: training on 3081926 raw words (2926372 effective words) took 3.6s, 805616 effective words/s\n",
      "2025-10-19 23:28:19,251 : INFO : EPOCH 26 - PROGRESS: at 26.40% examples, 771127 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:28:20,251 : INFO : EPOCH 26 - PROGRESS: at 57.53% examples, 836973 words/s, in_qsize 6, out_qsize 0\n",
      "2025-10-19 23:28:21,256 : INFO : EPOCH 26 - PROGRESS: at 82.98% examples, 804901 words/s, in_qsize 6, out_qsize 0\n",
      "2025-10-19 23:28:21,894 : INFO : EPOCH 26: training on 3081926 raw words (2926460 effective words) took 3.6s, 802369 effective words/s\n",
      "2025-10-19 23:28:22,904 : INFO : EPOCH 27 - PROGRESS: at 24.46% examples, 710824 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:28:23,912 : INFO : EPOCH 27 - PROGRESS: at 50.43% examples, 729156 words/s, in_qsize 6, out_qsize 0\n",
      "2025-10-19 23:28:24,932 : INFO : EPOCH 27 - PROGRESS: at 77.51% examples, 744576 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:28:25,827 : INFO : EPOCH 27: training on 3081926 raw words (2925919 effective words) took 3.9s, 744273 effective words/s\n",
      "2025-10-19 23:28:26,838 : INFO : EPOCH 28 - PROGRESS: at 23.52% examples, 682413 words/s, in_qsize 6, out_qsize 0\n",
      "2025-10-19 23:28:27,855 : INFO : EPOCH 28 - PROGRESS: at 50.69% examples, 730005 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:28:28,864 : INFO : EPOCH 28 - PROGRESS: at 78.43% examples, 754176 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:28:29,734 : INFO : EPOCH 28: training on 3081926 raw words (2925840 effective words) took 3.9s, 749081 effective words/s\n",
      "2025-10-19 23:28:30,740 : INFO : EPOCH 29 - PROGRESS: at 26.40% examples, 771059 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:28:31,748 : INFO : EPOCH 29 - PROGRESS: at 51.73% examples, 749446 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:28:32,752 : INFO : EPOCH 29 - PROGRESS: at 72.91% examples, 705809 words/s, in_qsize 5, out_qsize 0\n",
      "2025-10-19 23:28:33,704 : INFO : EPOCH 29: training on 3081926 raw words (2925570 effective words) took 4.0s, 737265 effective words/s\n",
      "2025-10-19 23:28:33,704 : INFO : Doc2Vec lifecycle event {'msg': 'training on 92457780 raw words (87778895 effective words) took 104.2s, 842406 effective words/s', 'datetime': '2025-10-19T23:28:33.704767', 'gensim': '4.4.0', 'python': '3.11.2 (main, Apr 28 2025, 14:11:48) [GCC 12.2.0]', 'platform': 'Linux-6.1.0-40-amd64-x86_64-with-glibc2.36', 'event': 'train'}\n",
      "2025-10-19 23:28:33,705 : INFO : Doc2Vec lifecycle event {'fname_or_handle': 'models/doc2vec_model.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-10-19T23:28:33.705243', 'gensim': '4.4.0', 'python': '3.11.2 (main, Apr 28 2025, 14:11:48) [GCC 12.2.0]', 'platform': 'Linux-6.1.0-40-amd64-x86_64-with-glibc2.36', 'event': 'saving'}\n",
      "2025-10-19 23:28:33,705 : INFO : storing np array 'vectors' to models/doc2vec_model.model.dv.vectors.npy\n",
      "2025-10-19 23:28:33,736 : INFO : not storing attribute cum_table\n",
      "2025-10-19 23:28:33,784 : INFO : saved models/doc2vec_model.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 1.74 mins\n"
     ]
    }
   ],
   "source": [
    "# Para treinar o modelo, será necessário associar uma tag/número com cada documento do corpus\n",
    "documents = [TaggedDocument(words=tokens, tags=[str(i)]) for i, tokens in enumerate(corpus)]\n",
    "\n",
    "d2v_model = Doc2Vec(\n",
    "    vector_size=300,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "t = time()\n",
    "d2v_model.build_vocab(documents, progress_per=10000)\n",
    "print(f'Time to build vocab: {round((time() - t) / 60, 2)}')\n",
    "\n",
    "t = time()\n",
    "d2v_model.train(documents, total_examples=d2v_model.corpus_count, epochs=d2v_model.epochs, report_delay=1)\n",
    "print(f'Time to train the model: {round((time() - t) / 60, 2)} mins')\n",
    "\n",
    "d2v_model.save('models/doc2vec_model.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44792cc1",
   "metadata": {},
   "source": [
    "### Exploração semântica\n",
    "Montando queries para comparar com os documentos do corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5571414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = ['sentir', 'ansioso', 'trabalho']\n",
    "# Infere-se um vetor de similaridade para a query utilizando o modelo.\n",
    "query_vector = d2v_model.infer_vector(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a13ae4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento 40274 -> Similaridade: 0.7841165065765381 <<alguma dica ansiedade trabalho poderia usar alguns conselhos>>\n",
      "Documento 26034 -> Similaridade: 0.7557452321052551 <<acompanho trabalho desde início 5potssempre fãabraço>>\n",
      "Documento 16062 -> Similaridade: 0.7436557412147522 <<ótima vida filhos esposa trabalho carreira resta arrependimento>>\n",
      "Documento 50087 -> Similaridade: 0.7339484691619873 <<desmoronei trabalho recuperar disso>>\n",
      "Documento 40861 -> Similaridade: 0.729849636554718 <<ansioso sábado>>\n"
     ]
    }
   ],
   "source": [
    "similar_docs = d2v_model.dv.most_similar([query_vector], topn=5)\n",
    "for tag, similarity in similar_docs:\n",
    "    print(f\"Documento {tag} -> Similaridade: {similarity} <<{' '.join(documents[int(tag)].words)}>>\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
