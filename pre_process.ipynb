{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4c4da2d",
   "metadata": {},
   "source": [
    "# NLP - Text preprocessing\n",
    "The pipeline steps were based on the following sources:\n",
    "- [https://sol.sbc.org.br/index.php/stil/article/download/31163/30966/](https://sol.sbc.org.br/index.php/stil/article/download/31163/30966/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbfc93cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# Import the corpus from a CSV\n",
    "df = pd.read_csv('data/DepreRedditBR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "427ef3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "372aabe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208601</th>\n",
       "      <td>não há nada que eu queira mais do que voltar n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462528</th>\n",
       "      <td>Lidando com mudanças de humor Tenho tido muita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76680</th>\n",
       "      <td>Se sua noiva não usar com voce, ja sabe. Não p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359032</th>\n",
       "      <td>muitas vezes não consigo trabalhar cerca de um...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353889</th>\n",
       "      <td>quais são suas ações quando você está se senti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271068</th>\n",
       "      <td>só estou vivo para outras pessoas e estou faze...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55861</th>\n",
       "      <td>Parabéns amigo! Você é o tapa buraco. Agora de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339906</th>\n",
       "      <td>ansiedade por estar doente, sou epiléptico e m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178869</th>\n",
       "      <td>Passei por um período muito difícil durante ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229866</th>\n",
       "      <td>eu não sei como sair. Estou fora da terapia de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50967 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text\n",
       "208601  não há nada que eu queira mais do que voltar n...\n",
       "462528  Lidando com mudanças de humor Tenho tido muita...\n",
       "76680   Se sua noiva não usar com voce, ja sabe. Não p...\n",
       "359032  muitas vezes não consigo trabalhar cerca de um...\n",
       "353889  quais são suas ações quando você está se senti...\n",
       "...                                                   ...\n",
       "271068  só estou vivo para outras pessoas e estou faze...\n",
       "55861   Parabéns amigo! Você é o tapa buraco. Agora de...\n",
       "339906  ansiedade por estar doente, sou epiléptico e m...\n",
       "178869    Passei por um período muito difícil durante ...\n",
       "229866  eu não sei como sair. Estou fora da terapia de...\n",
       "\n",
       "[50967 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=0.1, random_state=42)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "563a2a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208601</th>\n",
       "      <td>não há nada que eu queira mais do que voltar n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462528</th>\n",
       "      <td>Lidando com mudanças de humor Tenho tido muita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76680</th>\n",
       "      <td>Se sua noiva não usar com vocechavevirg ja sab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359032</th>\n",
       "      <td>muitas vezes não consigo trabalhar cerca de um...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353889</th>\n",
       "      <td>quais são suas ações quando você está se senti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271068</th>\n",
       "      <td>só estou vivo para outras pessoas e estou faze...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55861</th>\n",
       "      <td>Parabéns amigo! Você é o tapa buraco. Agora de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339906</th>\n",
       "      <td>ansiedade por estar doentechavevirg sou epilép...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178869</th>\n",
       "      <td>Passei por um período muito difícil durante ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229866</th>\n",
       "      <td>eu não sei como sair. Estou fora da terapia de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50967 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text\n",
       "208601  não há nada que eu queira mais do que voltar n...\n",
       "462528  Lidando com mudanças de humor Tenho tido muita...\n",
       "76680   Se sua noiva não usar com vocechavevirg ja sab...\n",
       "359032  muitas vezes não consigo trabalhar cerca de um...\n",
       "353889  quais são suas ações quando você está se senti...\n",
       "...                                                   ...\n",
       "271068  só estou vivo para outras pessoas e estou faze...\n",
       "55861   Parabéns amigo! Você é o tapa buraco. Agora de...\n",
       "339906  ansiedade por estar doentechavevirg sou epilép...\n",
       "178869    Passei por um período muito difícil durante ...\n",
       "229866  eu não sei como sair. Estou fora da terapia de...\n",
       "\n",
       "[50967 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace comma with 'chavevirg' label\n",
    "df = df.apply(lambda text: text.str.replace(r',', 'chavevirg'), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6526fba4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menelvo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnormaliser\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Normaliser\n\u001b[32m      5\u001b[39m normaliser_instance = Normaliser(tokenizer=\u001b[33m'\u001b[39m\u001b[33mreadable\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m df = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormaliser_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormalise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Remove URLs if there is any\u001b[39;00m\n\u001b[32m      9\u001b[39m df = df.apply(\u001b[38;5;28;01mlambda\u001b[39;00m text: re.sub(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttp\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mS+\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, text))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/Mestrado/nlp_text_pre_processing/.venv/lib/python3.11/site-packages/pandas/core/frame.py:9423\u001b[39m, in \u001b[36mDataFrame.apply\u001b[39m\u001b[34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[39m\n\u001b[32m   9412\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[32m   9414\u001b[39m op = frame_apply(\n\u001b[32m   9415\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   9416\u001b[39m     func=func,\n\u001b[32m   (...)\u001b[39m\u001b[32m   9421\u001b[39m     kwargs=kwargs,\n\u001b[32m   9422\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m9423\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mapply\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/Mestrado/nlp_text_pre_processing/.venv/lib/python3.11/site-packages/pandas/core/apply.py:678\u001b[39m, in \u001b[36mFrameApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    675\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw:\n\u001b[32m    676\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_raw()\n\u001b[32m--> \u001b[39m\u001b[32m678\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/Mestrado/nlp_text_pre_processing/.venv/lib/python3.11/site-packages/pandas/core/apply.py:798\u001b[39m, in \u001b[36mFrameApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    797\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m798\u001b[39m     results, res_index = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    800\u001b[39m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[32m    801\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.wrap_results(results, res_index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/Mestrado/nlp_text_pre_processing/.venv/lib/python3.11/site-packages/pandas/core/apply.py:814\u001b[39m, in \u001b[36mFrameApply.apply_series_generator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    811\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[33m\"\u001b[39m\u001b[33mmode.chained_assignment\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    812\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[32m    813\u001b[39m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m814\u001b[39m         results[i] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    815\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[32m    816\u001b[39m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[32m    817\u001b[39m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[32m    818\u001b[39m             results[i] = results[i].copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(row)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menelvo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnormaliser\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Normaliser\n\u001b[32m      5\u001b[39m normaliser_instance = Normaliser(tokenizer=\u001b[33m'\u001b[39m\u001b[33mreadable\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m df = df.apply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mnormaliser_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormalise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m, axis=\u001b[32m1\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Remove URLs if there is any\u001b[39;00m\n\u001b[32m      9\u001b[39m df = df.apply(\u001b[38;5;28;01mlambda\u001b[39;00m text: re.sub(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttp\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mS+\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, text))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/Mestrado/nlp_text_pre_processing/.venv/lib/python3.11/site-packages/enelvo/normaliser.py:146\u001b[39m, in \u001b[36mNormaliser.normalise\u001b[39m\u001b[34m(self, sentence)\u001b[39m\n\u001b[32m    140\u001b[39m     pp_line[i] = \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m.norm_lex[pp_line[i]], key=\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[32m1\u001b[39m])[\n\u001b[32m    141\u001b[39m         \u001b[32m0\u001b[39m\n\u001b[32m    142\u001b[39m     ]\n\u001b[32m    143\u001b[39m \u001b[38;5;66;03m# If a given noisy word has not been learnt, it is normalised\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;66;03m# by lexical similarity\u001b[39;00m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     cands = \u001b[43mcandidate_generation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_by_similarity_metric\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmain_lex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m        \u001b[49m\u001b[43mword\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpp_line\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_cands\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_cands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m     best_cand = candidate_scoring.score_by_similarity_metrics(\n\u001b[32m    153\u001b[39m         candidates=cands,\n\u001b[32m    154\u001b[39m         metrics=[metrics.hassan_similarity],\n\u001b[32m    155\u001b[39m         reverse=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    156\u001b[39m         n_cands=\u001b[32m1\u001b[39m,\n\u001b[32m    157\u001b[39m     )\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m best_cand[\u001b[32m1\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/Mestrado/nlp_text_pre_processing/.venv/lib/python3.11/site-packages/enelvo/candidate_generation/baselines.py:32\u001b[39m, in \u001b[36mgenerate_by_similarity_metric\u001b[39m\u001b[34m(lex, word, metric, threshold, geq, n_cands)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Comparison function changes according to ``geq`` flag.\u001b[39;00m\n\u001b[32m     30\u001b[39m comp = \u001b[38;5;28;01mlambda\u001b[39;00m x, y: x >= y \u001b[38;5;28;01mif\u001b[39;00m geq \u001b[38;5;28;01melse\u001b[39;00m x <= y\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m candidates = \u001b[38;5;28msorted\u001b[39m(\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcomp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# candidates = ([c for c in lex if comp(metric(word, c), threshold)])\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (word, candidates) \u001b[38;5;28;01mif\u001b[39;00m n_cands == -\u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m (word, candidates[:n_cands])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/Mestrado/nlp_text_pre_processing/.venv/lib/python3.11/site-packages/enelvo/candidate_generation/baselines.py:32\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Comparison function changes according to ``geq`` flag.\u001b[39;00m\n\u001b[32m     30\u001b[39m comp = \u001b[38;5;28;01mlambda\u001b[39;00m x, y: x >= y \u001b[38;5;28;01mif\u001b[39;00m geq \u001b[38;5;28;01melse\u001b[39;00m x <= y\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m candidates = \u001b[38;5;28msorted\u001b[39m([c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m lex \u001b[38;5;28;01mif\u001b[39;00m comp(\u001b[43mmetric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m, threshold)])\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# candidates = ([c for c in lex if comp(metric(word, c), threshold)])\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (word, candidates) \u001b[38;5;28;01mif\u001b[39;00m n_cands == -\u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m (word, candidates[:n_cands])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/Mestrado/nlp_text_pre_processing/.venv/lib/python3.11/site-packages/enelvo/metrics/metrics.py:43\u001b[39m, in \u001b[36medit_distance\u001b[39m\u001b[34m(str_x, str_y)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34medit_distance\u001b[39m(str_x: \u001b[38;5;28mstr\u001b[39m, str_y: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m     34\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Calculates the edit distance between two strings.\u001b[39;00m\n\u001b[32m     35\u001b[39m \n\u001b[32m     36\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m \u001b[33;03m        The edit distance between str_x and str_y. 0 = same string.\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43meditdistance\u001b[49m\u001b[43m.\u001b[49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_y\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Enelvo Text normaliser (https://thalesbertaglia.com/enelvo/)\n",
    "import re\n",
    "from enelvo.normaliser import Normaliser\n",
    "\n",
    "normaliser_instance = Normaliser(tokenizer='readable')\n",
    "df = df.apply(lambda row: normaliser_instance.normalise(row.text), axis=1)\n",
    "\n",
    "# Remove URLs if there is any\n",
    "df = df.apply(lambda text: re.sub(r'http\\S+', '', text))\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
